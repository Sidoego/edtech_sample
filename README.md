Всю аналитику мы делаем раз в сутки, это существенно упрощает архитектуру и снижает затраты так как нет необходимости держать постоянно работающие Flink/Spark-стримы.
Так же это обеспечивает 
- Простоту и стабильность: проще отлаживать, проще восстанавливать.
- Возможность использовать более дешевые, но медленные системы хранения
- Согласование данных — нет риска "вчерашних" и "сегодняшних" данных в одном отчете.

Обработка: один раз в сутки
Сырые события накапливаются и складываются в S3 или любое другое хранилище.
Ночью запускается Airflow DAG, который:
- Забирает события за D-1
- Преобразует их в нормализованный формат
- Обновляет агрегированные таблицы

Хранилище данных: ClickHouse
- Высокая скорость агрегаций и фильтраций
- Компактность хранения
- Прекрасно работает в batch-сценарии
  
